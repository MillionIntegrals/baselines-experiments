name: 'pong_trpo_oai'

env:
  name: vel.rl.env.classic_atari
  game: 'PongNoFrameskip-v4'


vec_env:
  name: vel.rl.vecenv.subproc
  frame_history: 4  # How many stacked frames go into a single observation


model:
  name: vel.rl.models.policy_gradient_model_separate

  policy_backbone:
    name: vel.rl.models.backbone.nature_cnn_small
    input_width: 84
    input_height: 84
    input_channels: 4  # The same as frame_history

  value_backbone:
    name: vel.rl.models.backbone.nature_cnn_small
    input_width: 84
    input_height: 84
    input_channels: 4  # The same as frame_history


reinforcer:
  name: vel.rl.reinforcers.on_policy_iteration_reinforcer

  algo:
    name: vel.rl.algo.policy_gradient.trpo
    max_kl: 0.001
    cg_iters: 10
    cg_damping: 0.001

    line_search_iters: 10
    improvement_acceptance_ratio: 0.1
    vf_iters: 3

    entropy_coef: 0.0
  #    max_grad_norm: 0.5

  env_roller:
    name: vel.rl.env_roller.vec.step_env_roller
    gae_lambda: 1.00 # Generalized Advantage Estimator Lambda parameter

  # In openAI baselines they rollout single env for 512 steps.
  # I roll out 16 envs for 32 steps in parallel

  number_of_steps: 32 # How many environment steps go into a single batch
  parallel_envs: 16 # How many environments to run in parallel
  discount_factor: 0.98
  batch_size: 512


optimizer:
  name: vel.optimizers.adam
  lr: 1.0e-4
  epsilon: 1.0e-8


#scheduler:
#  name: vel.scheduler.linear_batch_scaler


commands:
  train:
    name: vel.rl.commands.rl_train_command
    total_frames: 1.1e7
    batches_per_epoch: 10

  record:
    name: vel.rl.commands.record_movie_command
    takes: 10
    videoname: 'pong_vid_{:04}.avi'
    frame_history: 4
    sample_args:
      argmax_sampling: true
